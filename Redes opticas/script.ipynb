{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo de ejecucion del codigo de redes opticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 4724 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1966         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007170341 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.3e+09      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000765    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.47e+09     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1626          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053237396 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.21e+09      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000557     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.39e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1523          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048451274 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.26e+09      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000489     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.39e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1463          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051230256 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.25e+09      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000557     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.39e+09      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1418         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003854704 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.29e+09     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000384    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.4e+09      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1378         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004594091 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.1e+09      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000455    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.47e+09     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005675955 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.31e+09     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000568    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.43e+09     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1346          |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 54            |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035870518 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.16e+09      |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000338     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.39e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1333          |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 61            |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042821086 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.11e+09      |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.000445     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.38e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1330          |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 67            |\n",
      "|    total_timesteps      | 90112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033062056 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.2e+09       |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000307     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.38e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1327          |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 74            |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043938519 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.09e+09      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000449     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.4e+09       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004073197 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.27e+09     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00041     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.46e+09     |\n",
      "------------------------------------------\n",
      "[array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812]), array([-1499921.92382812, -1499921.92382812, -1499921.92382812,\n",
      "       -1499921.92382812])]\n",
      "Recompensa promedio en los episodios de prueba: -1499921.923828125\n",
      "Objetivo no alcanzado.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from custom_env.redes_opticas_env import RedesOpticasEnv  # Asegúrate de que esta ruta sea correcta\n",
    "\n",
    "def make_env(env_id: str, rank: int, seed: int):\n",
    "    def _init():\n",
    "        try:\n",
    "            env = gym.make(env_id, render_mode=None)  # Cambia a None si no quieres modo visual\n",
    "            env.reset(seed=seed + rank)\n",
    "            return env\n",
    "        except Exception as e:\n",
    "            print(f\"Error al inicializar el entorno: {e}\")\n",
    "            raise e\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_id = 'RedesOpticasEnv-v0'  # Asegúrate de que este ID coincida con el registrado\n",
    "    num_cpu = 4  # Reduce el número si es necesario\n",
    "    seed = np.random.randint(0, 10)\n",
    "    vec_env = DummyVecEnv([make_env(env_id, i, seed) for i in range(num_cpu)])\n",
    "    model = PPO(\"MultiInputPolicy\", vec_env, verbose=1, n_steps=2048)\n",
    "    model.learn(total_timesteps=100_000)\n",
    "\n",
    "    # Fase de prueba\n",
    "    num_test_episodes = 10  # Número de episodios de prueba\n",
    "    episode_rewards = []  # Lista para guardar las recompensas totales de cada episodio de prueba\n",
    "\n",
    "    for episode in range(num_test_episodes):\n",
    "        obs = vec_env.reset()  # Resetea el entorno al estado inicial\n",
    "        done = np.array([False]*num_cpu)  # Inicializa 'done' para todos los entornos\n",
    "        total_rewards = np.array([0.0]*num_cpu)  # Inicializa la recompensa total por entorno\n",
    "        \n",
    "        while not done.all():\n",
    "            action, _states = model.predict(obs, deterministic=True)  # Usa el modelo para predecir la acción\n",
    "            obs, rewards, dones, info = vec_env.step(action)  # Ejecuta la acción en el entorno\n",
    "            total_rewards += rewards  # Acumula las recompensas\n",
    "            done |= dones \n",
    "        \n",
    "        episode_rewards.append(total_rewards)  # Guarda las recompensas totales de este episodio\n",
    "\n",
    "    # Análisis de los resultados de la prueba\n",
    "    print(episode_rewards)\n",
    "    recompensa_promedio = np.mean(episode_rewards)\n",
    "\n",
    "    print(f\"Recompensa promedio en los episodios de prueba: {recompensa_promedio}\")\n",
    "    objetivo_deseado = 500  # En nuestro caso el objetivo es acercarnos al Balloc = 500\n",
    "    if recompensa_promedio >= objetivo_deseado:\n",
    "        print(\"¡Objetivo alcanzado!\")\n",
    "    else:\n",
    "        print(\"Objetivo no alcanzado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
